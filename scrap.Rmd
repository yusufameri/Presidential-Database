---
title: "Election Scraping"
author: "Yusuf Ameri"
date: "11/4/2016"
output: html_document
---

```{r libraries}
library(rvest)
library(dplyr)
library(tidyr)
library(magrittr)
```
### Step 1: Scrap the many Tables
We need to scrap the many many tables located on [this link](https://www.archives.gov/federal-register/electoral-college/scores.html). As you can see, there are many tables and each table has a different number of rows (some include notes and popular vote while others do not). The first task at hand is to try to select these html tables via an x-path. I used [selectorgadget](http://selectorgadget.com/), but I think you could use plain old developer tools on chrome to do this too (I tried using chrome inspector from the developer tools for a few hours but could not figure it out.). Luckily, what I found out was that the x-path that selectorgadget made for me followed a very specific formula and all I had to do was change a single number to iterate and grab each table. The code below demonstrates be generating the xpaths (line number 33 in the for loop). 
```{r scrape}
library(htmltab)

url <- "https://www.archives.gov/federal-register/electoral-college/scores.html"

# Access a table via below xpath
new_xpath <- '//tr[(((count(preceding-sibling::*) + 1) = 3) and parent::*)]//table'

# xpath follows a specific string concatination formula. Each table is every other number from 1
# to 105. Concatinating base1, a number, and base2, allows us to access said table on election
table_numbers <- seq(from=1, to=105, by=2)
base1 <- '//tr[(((count(preceding-sibling::*) + 1) = '
base2 <- ') and parent::*)]//table'

# create xpaths for each table to scrape
for(var in table_numbers) {
  x_path <- paste(base1,var,base2,sep="")
}

elections <- t(htmltab(doc = url, which = new_xpath))
elections <- elections[1:3,]

# make the first row the column names
colnames(elections) <- elections[1,]

# remove the first row from the df
elections <- elections[-c(1),]
head(t(elections))
```
